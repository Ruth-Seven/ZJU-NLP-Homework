{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os.path\n",
    "import sys\n",
    "\n",
    "import re\n",
    "import zhconv\n",
    "import jieba\n",
    "from gensim.corpora import WikiCorpus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-09-24 08:44:07,304_INFO:\n",
      "\n",
      "------------------------\n",
      "Running C:\\Users\\ruth\\anaconda3\\envs\\mldl_cuda_py37\\lib\\site-packages\\ipykernel_launcher.py-fC:\\Users\\ruth\\AppData\\Roaming\\jupyter\\runtime\\kernel-f7c68893-a28f-4795-a4b0-5946d77c5463.json\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "#     program = os.path.basename(sys.argv[0])\n",
    "#     logger = logging.getLogger(program)\n",
    "\n",
    "    logger = logging.getLogger(\"PROCESSING PROGRAM\")\n",
    "    logging.basicConfig(format='%(asctime)s_%(levelname)s:%(message)s')\n",
    "    logger.setLevel(level=logging.INFO)\n",
    "    logger.info(\"\\n\\n------------------------\\nRunning %s\" % \"\".join(sys.argv))\n",
    "\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    if len(sys.argv) < 3:\n",
    "#         # print( globals() ['__doc__'])\n",
    "#         # print(globals()['__doc__'] % locals())\n",
    "#         # print(globals())\n",
    "#         # print( locals())\n",
    "#         logger.error(\"I neede more parameter!\")\n",
    "#         sys.exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    inp, outp = sys.argv[1:3]\n",
    "    space = \" \"\n",
    "    i = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp  = \"zhwiki-latest-pages-articles.xml.bz2\"\n",
    "outp = \"zhwiki.text\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#test function.\n",
    "wiki = WikiCorpus(inp, lemmatize=False, dictionary={})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text = wiki.get_texts().__next__()\n",
    "print(type(text))\n",
    "print(str(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "text_hans = zhconv.convert( \" \".join(text),'zh-hans')\n",
    "text_hansh"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "words_jieba = \" \".join(jieba.cut(text_hans.replace(' ', ''))) + '\\n'\n",
    "words_jieba"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "cn_reg = r'([\\u4e00-\\u9fa5]+)'  #\n",
    "\n",
    "# if(re.search(cn_reg, words_line)):\n",
    "#选出所有中文字词并用空格连接起来\n",
    "cnwords = re.findall(cn_reg, words_line)\n",
    "print(cnwords);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "line = \" \".join(cnwords)\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ruth\\anaconda3\\envs\\mldl_cuda_py37\\lib\\site-packages\\gensim\\utils.py:1254: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "Building prefix dict from the default dictionary ...\n",
      "2020-09-24 08:46:17,915_DEBUG:Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\jieba.cache\n",
      "2020-09-24 08:46:17,943_DEBUG:Loading model from cache C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\jieba.cache\n",
      "Loading model cost 1.006 seconds.\n",
      "2020-09-24 08:46:18,927_DEBUG:Loading model cost 1.006 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-09-24 08:46:18,930_DEBUG:Prefix dict has been built successfully.\n",
      "2020-09-24 08:50:05,237_INFO:Saved 10000 articles and 12018301 words. \n",
      "2020-09-24 08:52:32,019_INFO:Saved 20000 articles and 20712157 words. \n",
      "2020-09-24 08:54:49,073_INFO:Saved 30000 articles and 28379015 words. \n",
      "2020-09-24 08:56:53,376_INFO:Saved 40000 articles and 35518113 words. \n",
      "2020-09-24 08:58:59,971_INFO:Saved 50000 articles and 42135221 words. \n",
      "2020-09-24 09:00:58,646_INFO:Saved 60000 articles and 48343422 words. \n",
      "2020-09-24 09:02:53,482_INFO:Saved 70000 articles and 54290193 words. \n",
      "2020-09-24 09:04:48,924_INFO:Saved 80000 articles and 59991818 words. \n",
      "2020-09-24 09:06:41,138_INFO:Saved 90000 articles and 65359150 words. \n",
      "2020-09-24 09:08:29,142_INFO:Saved 100000 articles and 70760682 words. \n",
      "2020-09-24 09:10:27,201_INFO:Saved 110000 articles and 76128397 words. \n",
      "2020-09-24 09:12:12,661_INFO:Saved 120000 articles and 81167027 words. \n",
      "2020-09-24 09:14:05,338_INFO:Saved 130000 articles and 86176876 words. \n",
      "2020-09-24 09:16:01,435_INFO:Saved 140000 articles and 91403261 words. \n",
      "2020-09-24 09:17:46,502_INFO:Saved 150000 articles and 96302198 words. \n",
      "2020-09-24 09:19:35,813_INFO:Saved 160000 articles and 101248997 words. \n",
      "2020-09-24 09:21:24,923_INFO:Saved 170000 articles and 106407157 words. \n",
      "2020-09-24 09:23:09,178_INFO:Saved 180000 articles and 111319338 words. \n",
      "2020-09-24 09:25:01,245_INFO:Saved 190000 articles and 115687675 words. \n",
      "2020-09-24 09:29:37,302_INFO:Saved 200000 articles and 119783462 words. \n",
      "2020-09-24 09:37:21,156_INFO:Saved 210000 articles and 124169104 words. \n",
      "2020-09-24 09:39:17,108_INFO:Saved 220000 articles and 128718357 words. \n",
      "2020-09-24 09:41:14,513_INFO:Saved 230000 articles and 133476640 words. \n",
      "2020-09-24 09:43:11,835_INFO:Saved 240000 articles and 138191519 words. \n",
      "2020-09-24 09:45:04,501_INFO:Saved 250000 articles and 142792616 words. \n",
      "2020-09-24 09:47:05,487_INFO:Saved 260000 articles and 147727861 words. \n",
      "2020-09-24 09:49:00,377_INFO:Saved 270000 articles and 152708958 words. \n",
      "2020-09-24 09:50:56,318_INFO:Saved 280000 articles and 157520337 words. \n",
      "2020-09-24 09:52:42,187_INFO:Saved 290000 articles and 161931939 words. \n",
      "2020-09-24 09:54:19,311_INFO:Saved 300000 articles and 166015524 words. \n",
      "2020-09-24 09:56:06,050_INFO:Saved 310000 articles and 170241357 words. \n",
      "2020-09-24 09:57:53,687_INFO:Saved 320000 articles and 174606758 words. \n",
      "2020-09-24 09:59:50,551_INFO:Saved 330000 articles and 179297970 words. \n",
      "2020-09-24 10:01:43,099_INFO:Saved 340000 articles and 183974493 words. \n",
      "2020-09-24 10:03:37,410_INFO:Saved 350000 articles and 188383480 words. \n",
      "2020-09-24 10:05:36,820_INFO:Saved 360000 articles and 193066454 words. \n",
      "2020-09-24 10:07:32,321_INFO:Saved 370000 articles and 197664529 words. \n",
      "2020-09-24 10:08:01,177_INFO:Finished Saved 372433 articles and 198690724 words.\n"
     ]
    }
   ],
   "source": [
    "with open(outp, \"w\", encoding='utf-8') as outfile:\n",
    "    wiki = WikiCorpus(inp, lemmatize=False, dictionary={})\n",
    "    i = 0\n",
    "    word_count = 0\n",
    "    for text in wiki.get_texts():     \n",
    "        # 将list转化为简体的str\n",
    "        text_hans = zhconv.convert( \" \".join(text),'zh-hans')\n",
    "        # 用已有的模块分词\n",
    "        words_jieba = \" \".join(jieba.cut(text_hans.replace(' ', ''))) + '\\n'\n",
    "\n",
    "        # 筛选出中文字符\n",
    "        cn_reg = r'([\\u4e00-\\u9fa5]+)'  #        \n",
    "        # 选出所有中文字词并用空格连接起来        \n",
    "        wordlist = re.findall(cn_reg, words_jieba)\n",
    "        line = \" \".join(wordlist)\n",
    "\n",
    "        \n",
    "        word_count = word_count + len(wordlist)\n",
    "        i = i + 1\n",
    "        #保存“一行”文字\n",
    "        outfile.write(line + \"\\n\")\n",
    "        if(i % 10000 == 0):\n",
    "            logger.info('Saved %d articles and %d words. ' % (i, word_count))\n",
    "    logger.info(\"Finished Saved %d articles and %d words.\" % (i, word_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}